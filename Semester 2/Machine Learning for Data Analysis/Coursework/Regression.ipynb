{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riley\\AppData\\Local\\Temp\\ipykernel_28592\\2890702488.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_merseybeat</th>\n",
       "      <th>genre_neo mellow</th>\n",
       "      <th>genre_new wave pop</th>\n",
       "      <th>genre_permanent wave</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_r&amp;b</th>\n",
       "      <th>genre_rock-and-roll</th>\n",
       "      <th>genre_soft rock</th>\n",
       "      <th>genre_uk garage</th>\n",
       "      <th>genre_yodeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>107</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>-8</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>114</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>-8</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1979</td>\n",
       "      <td>105</td>\n",
       "      <td>36</td>\n",
       "      <td>63</td>\n",
       "      <td>-9</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1980</td>\n",
       "      <td>170</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>-16</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1973</td>\n",
       "      <td>121</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>-8</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  year  bpm  nrgy  dnce  dB  live  val  dur  ...  \\\n",
       "0           0   1  1996  107    31    45  -8    13   28  150  ...   \n",
       "1           1   2  2011  114    44    53  -8    13   47  139  ...   \n",
       "2           2   3  1979  105    36    63  -9    13   67  245  ...   \n",
       "3           3   4  1980  170    28    47 -16    13   33  232  ...   \n",
       "4           4   5  1973  121    47    56  -8    15   40  193  ...   \n",
       "\n",
       "   genre_merseybeat  genre_neo mellow  genre_new wave pop  \\\n",
       "0               0.0               0.0                 0.0   \n",
       "1               0.0               0.0                 0.0   \n",
       "2               0.0               0.0                 0.0   \n",
       "3               0.0               0.0                 0.0   \n",
       "4               0.0               0.0                 0.0   \n",
       "\n",
       "   genre_permanent wave  genre_pop  genre_r&b  genre_rock-and-roll  \\\n",
       "0                   0.0        0.0        0.0                  0.0   \n",
       "1                   0.0        0.0        0.0                  0.0   \n",
       "2                   0.0        0.0        0.0                  0.0   \n",
       "3                   0.0        0.0        0.0                  0.0   \n",
       "4                   0.0        0.0        0.0                  0.0   \n",
       "\n",
       "   genre_soft rock  genre_uk garage  genre_yodeling  \n",
       "0              0.0              0.0             0.0  \n",
       "1              0.0              0.0             0.0  \n",
       "2              0.0              0.0             0.0  \n",
       "3              0.0              0.0             0.0  \n",
       "4              0.0              0.0             0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Training_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(['pop'],axis=1)\n",
    "y = df[\"pop\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199241858329917.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "\n",
    "y_pred = reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- very poor mse , probably better options out there "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Decent Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16547671316223.422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sgd_reg = SGDRegressor(random_state=42)\n",
    "sgd_reg.fit(x_train, y_train)\n",
    "sgd_reg.score(x_train,y_train)\n",
    "sgd_reg.coef_\n",
    "sgd_reg.intercept_\n",
    "\n",
    "y_pred = sgd_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Score is much larger than expeceted \n",
    "- Fluxuating hyperparameters doesn't seem to change the score all too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear/Polynomial Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.776477572551993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2,include_bias=False)\n",
    "\n",
    "x_poly = poly.fit_transform(x_train)\n",
    "\n",
    "poly.fit(x_train, y_train)\n",
    "\n",
    "lin_poly=LinearRegression().fit(x_poly, y_train)\n",
    "\n",
    "y_pred = lin_poly.predict(poly.fit_transform(x_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: \n",
    "- Better than SGD but worse than simple linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:18.72413967565417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "Log_reg = LogisticRegression(max_iter=1000,random_state=42) # Not necessary to parameterise\n",
    "Log_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = Log_reg.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes \n",
    "- Better than Non-Linear however im scheptical of any improvements that can be made to it. \n",
    "- Worse than simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:15.438507321414347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=8,random_state=42)\n",
    "svm_reg.fit(x_train,y_train)\n",
    "y_pred = svm_reg.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Not bad , still lower than previous attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:14.940265675734768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DT_reg= DecisionTreeRegressor(criterion='friedman_mse', max_depth=20,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, random_state=42,\n",
    "            splitter='best')\n",
    "DT_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = DT_reg.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Still not the best we've seen however definitely promising with some tuning. \n",
    "- Theory & parameters are easier to understand so might be worth circling back to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressors Selection  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the proper modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessery libraries & pre-processing \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures , StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import all relevant regressors from sklearn  \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge,ElasticNet,LogisticRegression,SGDRegressor,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset \n",
    "In order to train the regressors , we will use the cleaned/processed training datasets created in the [Analysis-Riley.ipynb](Analysis-Riley.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"Training_Cleaned.csv\")\n",
    "df.head()\n",
    "x = df.drop(columns=['pop','Id'])\n",
    "y = df[\"pop\"]\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Random state\n",
    ">\"Using random_state is important for reproducibility, debugging, and comparison of results. By setting this parameter, you can >ensure that your experiments are reproducible, debug problems more effectively, and compare the performance of different models >more accurately\" -[What Is 'random_state' in sklearn.model_selection.train_test_split Example?](https://saturncloud.io/blog/what-is-randomstate-in-sklearnmodelselectiontraintestsplit-example/#:~:text=Using%20random_state%20is%20important%20for%20reproducibility%2C%20debugging%2C%20and%20comparison%20of,of%20different%20models%20more%20accurately.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling the regressors \n",
    "From here we can adjust the hyperparameters adjust the performance of each one.\n",
    "\n",
    "#### GradientBoostingRegressor (GBR)\n",
    "- Gradient Boosting is an ensemble learning technique that builds models sequentially, with each model trying to correct the    errors of its predecessor. The default settings are often a good starting point.\n",
    "KernelRidge (KR):\n",
    "\n",
    "#### Kernel Ridge Regression\n",
    "- Combines Ridge Regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear data, this can be very effective.\n",
    "BayesianRidge (BR):\n",
    "\n",
    "#### Bayesian Ridge Regression \n",
    "- implements Bayesian linear regression. It is particularly useful when the size of the data is not too large and you want to include regularization parameters that are tuned to the data.\n",
    "\n",
    "#### ElasticNet (EN)\n",
    "- ElasticNet is a linear regression model trained with both l1 and l2-norm regularization of the coefficients. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge.\n",
    "\n",
    "#### DecisionTreeRegressor (DT)\n",
    "- 'friedman_mse' criterion measures the quality of a split based on mean squared error with improvement score by Friedman. It's often a good choice for regression.\n",
    "- 'max_depth=20' sets a limit on the depth of the tree. Deep trees can lead to overfitting.\n",
    "\n",
    "Other parameters like 'max_features', 'max_leaf_nodes', and 'min_impurity_decrease' are set to their default values, which are generally a good starting point.\n",
    "- 'min_samples_leaf' and 'min_samples_split' control the size of the leaf nodes and splits, influencing model complexity.\n",
    "- 'random_state' ensures reproducibility.\n",
    "- 'splitter=best' chooses the best split at each node.\n",
    "\n",
    "#### LinearSVR\n",
    "- 'epsilon=8' defines the margin of tolerance where no penalty is given to errors. The choice of this value can significantly affect the fit.\n",
    "- 'random_state' for reproducibility.\n",
    "\n",
    "#### SVR with Polynomial Kernel (Poly_SVR)\n",
    "- 'kernel=\"poly\"' specifies the use of a polynomial kernel.\n",
    "- 'degree=2' for the polynomial kernel. A degree of 2 usually captures non-linear relationships well without overfitting.\n",
    "- 'C=1' sets the regularization parameter. A smaller value of C means more regularization.\n",
    "- 'epsilon=0.1' sets the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.\n",
    "- 'gamma=\"scale\"' automatically adjusts gamma based on the number of features, which often leads to better performance.\n",
    "\n",
    "#### LogisticRegression\n",
    "Used for classification problems. The default parameters are often a reasonable starting point.\n",
    "- 'random_state' for reproducibility.\n",
    "\n",
    "#### SGDRegressor\n",
    "Stochastic Gradient Descent is a simple yet very efficient approach to fitting linear models.\n",
    "- 'random_state' for reproducibility.\n",
    "\n",
    "### LinearRegression\n",
    "Standard linear regression without regularization. It's the most basic form of regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor()\n",
    "KR = KernelRidge()\n",
    "BR = BayesianRidge()\n",
    "EN = ElasticNet()\n",
    "DT = DecisionTreeRegressor(criterion='friedman_mse', max_depth=20,\n",
    "                        max_features=None, max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0,\n",
    "                        min_samples_leaf=1, min_samples_split=2,\n",
    "                        min_weight_fraction_leaf=0.0, random_state=random_state,\n",
    "                        splitter='best')\n",
    "Lin_SVR = LinearSVR(epsilon = 8 , random_state=random_state )\n",
    "Poly_SVR = SVR(kernel=\"poly\", degree=2, C=1, epsilon=0.1, gamma=\"scale\")\n",
    "Log_reg = LogisticRegression(random_state=random_state)\n",
    "SGD = SGDRegressor(random_state=random_state)\n",
    "Lin_reg = LinearRegression()\n",
    "\n",
    "# Combining these models into a list allows for a simple training/testing function to be used for each of them. \n",
    "reg_list = [GBR,KR,BR,DT, Lin_SVR, Lin_reg, Log_reg, SGD,Poly_SVR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_scaler = StandardScaler()\n",
    "x_train = std_scaler.fit_transform(x_train)\n",
    "x_test = std_scaler.fit_transform(x_test)\n",
    "\n",
    "def use_regressor(reg):\n",
    "    regressor = reg.fit(x_train,y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    mse=mean_squared_error(y_test,y_pred)\n",
    "    print(f\"MSE:{np.sqrt(mse)} for {reg.__class__.__name__}\")\n",
    "    return y_pred\n",
    "\n",
    "for reg in reg_list:\n",
    "    use_regressor(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Training_Cleaned.csv\")\n",
    "df.head()\n",
    "x_train = df.drop(columns=['pop'])\n",
    "y_train = df[\"pop\"]\n",
    "x_test = pd.read_csv(\"Testing_Cleaned.csv\")\n",
    "predictions = pd.DataFrame(x_test['Id']) \n",
    "#predictions.insert(1,'pop','NaN')\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "x_train = std_scaler.fit_transform(x_train)\n",
    "x_test = std_scaler.fit_transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge,ElasticNet,LogisticRegression,SGDRegressor,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures , StandardScaler\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "GBR = GradientBoostingRegressor(learning_rate=0.1, max_depth= 3, min_samples_leaf= 1, min_samples_split= 2, n_estimators=100)\n",
    "KR = KernelRidge(alpha= 0.1, kernel='linear')\n",
    "BR = BayesianRidge(alpha_1= 1e-05, alpha_2= 1e-06, lambda_1= 1e-06, lambda_2= 1e-05, n_iter= 300)\n",
    "EN = ElasticNet(alpha= 0.1, l1_ratio= 0.8)\n",
    "DT = DecisionTreeRegressor(max_depth= 10, min_samples_leaf=10, min_samples_split= 2)\n",
    "Lin_SVR = LinearSVR(C= 0.1, epsilon= 0.2 , random_state=random_state )\n",
    "Poly_SVR = SVR(kernel=\"poly\", degree=2, C=1, epsilon=0.1, gamma=\"scale\")\n",
    "Log_reg = LogisticRegression(random_state=random_state)\n",
    "SGD = SGDRegressor(random_state=random_state)\n",
    "Lin_reg = LinearRegression()\n",
    "\n",
    "\n",
    "reg_list = [GBR,KR,BR,DT, Lin_SVR, Lin_reg, Log_reg, SGD,Poly_SVR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_bayes.py:53: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\n",
      "  warnings.warn(\n",
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_list:\n",
    "    regressor = reg.fit(x_train,y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    predictions_list = list(y_pred)\n",
    "    predictions['pop']= predictions_list\n",
    "    predictions.to_csv(f'{reg.__class__.__name__}_pop_predictions.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
