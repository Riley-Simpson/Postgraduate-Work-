{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riley\\AppData\\Local\\Temp\\ipykernel_28592\\2890702488.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_merseybeat</th>\n",
       "      <th>genre_neo mellow</th>\n",
       "      <th>genre_new wave pop</th>\n",
       "      <th>genre_permanent wave</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_r&amp;b</th>\n",
       "      <th>genre_rock-and-roll</th>\n",
       "      <th>genre_soft rock</th>\n",
       "      <th>genre_uk garage</th>\n",
       "      <th>genre_yodeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>107</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>-8</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>114</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>-8</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1979</td>\n",
       "      <td>105</td>\n",
       "      <td>36</td>\n",
       "      <td>63</td>\n",
       "      <td>-9</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1980</td>\n",
       "      <td>170</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>-16</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1973</td>\n",
       "      <td>121</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>-8</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  year  bpm  nrgy  dnce  dB  live  val  dur  ...  \\\n",
       "0           0   1  1996  107    31    45  -8    13   28  150  ...   \n",
       "1           1   2  2011  114    44    53  -8    13   47  139  ...   \n",
       "2           2   3  1979  105    36    63  -9    13   67  245  ...   \n",
       "3           3   4  1980  170    28    47 -16    13   33  232  ...   \n",
       "4           4   5  1973  121    47    56  -8    15   40  193  ...   \n",
       "\n",
       "   genre_merseybeat  genre_neo mellow  genre_new wave pop  \\\n",
       "0               0.0               0.0                 0.0   \n",
       "1               0.0               0.0                 0.0   \n",
       "2               0.0               0.0                 0.0   \n",
       "3               0.0               0.0                 0.0   \n",
       "4               0.0               0.0                 0.0   \n",
       "\n",
       "   genre_permanent wave  genre_pop  genre_r&b  genre_rock-and-roll  \\\n",
       "0                   0.0        0.0        0.0                  0.0   \n",
       "1                   0.0        0.0        0.0                  0.0   \n",
       "2                   0.0        0.0        0.0                  0.0   \n",
       "3                   0.0        0.0        0.0                  0.0   \n",
       "4                   0.0        0.0        0.0                  0.0   \n",
       "\n",
       "   genre_soft rock  genre_uk garage  genre_yodeling  \n",
       "0              0.0              0.0             0.0  \n",
       "1              0.0              0.0             0.0  \n",
       "2              0.0              0.0             0.0  \n",
       "3              0.0              0.0             0.0  \n",
       "4              0.0              0.0             0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Training_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(['pop'],axis=1)\n",
    "y = df[\"pop\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199241858329917.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "\n",
    "y_pred = reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- very poor mse , probably better options out there "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Decent Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16547671316223.422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sgd_reg = SGDRegressor(random_state=42)\n",
    "sgd_reg.fit(x_train, y_train)\n",
    "sgd_reg.score(x_train,y_train)\n",
    "sgd_reg.coef_\n",
    "sgd_reg.intercept_\n",
    "\n",
    "y_pred = sgd_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Score is much larger than expeceted \n",
    "- Fluxuating hyperparameters doesn't seem to change the score all too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear/Polynomial Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.776477572551993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2,include_bias=False)\n",
    "\n",
    "x_poly = poly.fit_transform(x_train)\n",
    "\n",
    "poly.fit(x_train, y_train)\n",
    "\n",
    "lin_poly=LinearRegression().fit(x_poly, y_train)\n",
    "\n",
    "y_pred = lin_poly.predict(poly.fit_transform(x_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: \n",
    "- Better than SGD but worse than simple linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:18.72413967565417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "Log_reg = LogisticRegression(max_iter=1000,random_state=42) # Not necessary to parameterise\n",
    "Log_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = Log_reg.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes \n",
    "- Better than Non-Linear however im scheptical of any improvements that can be made to it. \n",
    "- Worse than simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:15.438507321414347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=8,random_state=42)\n",
    "svm_reg.fit(x_train,y_train)\n",
    "y_pred = svm_reg.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Not bad , still lower than previous attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:14.940265675734768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DT_reg= DecisionTreeRegressor(criterion='friedman_mse', max_depth=20,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, random_state=42,\n",
    "            splitter='best')\n",
    "DT_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = DT_reg.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"MSE:{np.sqrt(mse)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Still not the best we've seen however definitely promising with some tuning. \n",
    "- Theory & parameters are easier to understand so might be worth circling back to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning + Other Regressors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:10.957591025798855 for GradientBoostingRegressor\n",
      "MSE:60.2713472855601 for KernelRidge\n",
      "MSE:12.586950045893003 for BayesianRidge\n",
      "MSE:16.72137541006707 for DecisionTreeRegressor\n",
      "MSE:12.415226644397654 for LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:41835074403729.23 for LinearRegression\n",
      "MSE:15.361933829730258 for LogisticRegression\n",
      "MSE:12.85908818062765 for SGDRegressor\n",
      "MSE:15.223828938752092 for SVR\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"Training_Cleaned.csv\")\n",
    "df.head()\n",
    "x = df.drop(columns=['pop','Id'])\n",
    "y = df[\"pop\"]\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge,ElasticNet,LogisticRegression,SGDRegressor,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures , StandardScaler\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "GBR = GradientBoostingRegressor()\n",
    "KR = KernelRidge()\n",
    "BR = BayesianRidge()\n",
    "EN = ElasticNet()\n",
    "DT = DecisionTreeRegressor(criterion='friedman_mse', max_depth=20,\n",
    "                        max_features=None, max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0,\n",
    "                        min_samples_leaf=1, min_samples_split=2,\n",
    "                        min_weight_fraction_leaf=0.0, random_state=random_state,\n",
    "                        splitter='best')\n",
    "Lin_SVR = LinearSVR(epsilon = 8 , random_state=random_state )\n",
    "Poly_SVR = SVR(kernel=\"poly\", degree=2, C=1, epsilon=0.1, gamma=\"scale\")\n",
    "Log_reg = LogisticRegression(random_state=random_state)\n",
    "SGD = SGDRegressor(random_state=random_state)\n",
    "Lin_reg = LinearRegression()\n",
    "\n",
    "reg_list = [GBR,KR,BR,DT, Lin_SVR, Lin_reg, Log_reg, SGD,Poly_SVR]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "x_train = std_scaler.fit_transform(x_train)\n",
    "x_test = std_scaler.fit_transform(x_test)\n",
    "\n",
    "def use_regressor(reg):\n",
    "    regressor = reg.fit(x_train,y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    mse=mean_squared_error(y_test,y_pred)\n",
    "    print(f\"MSE:{np.sqrt(mse)} for {reg.__class__.__name__}\")\n",
    "    return y_pred\n",
    "\n",
    "for reg in reg_list:\n",
    "    use_regressor(reg) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Training_Cleaned.csv\")\n",
    "df.head()\n",
    "x_train = df.drop(columns=['pop'])\n",
    "y_train = df[\"pop\"]\n",
    "x_test = pd.read_csv(\"Testing_Cleaned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge,ElasticNet,LogisticRegression,SGDRegressor,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures , StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "GBR = GradientBoostingRegressor()\n",
    "KR = KernelRidge()\n",
    "BR = BayesianRidge()\n",
    "EN = ElasticNet()\n",
    "DT = DecisionTreeRegressor(criterion='friedman_mse', max_depth=20,\n",
    "                        max_features=None, max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0,\n",
    "                        min_samples_leaf=1, min_samples_split=2,\n",
    "                        min_weight_fraction_leaf=0.0, random_state=random_state,\n",
    "                        splitter='best')\n",
    "Lin_SVR = LinearSVR(epsilon = 8 , random_state=random_state )\n",
    "Poly_SVR = SVR(kernel=\"poly\", degree=2, C=1, epsilon=0.1, gamma=\"scale\")\n",
    "Log_reg = LogisticRegression(random_state=random_state)\n",
    "SGD = SGDRegressor(random_state=random_state)\n",
    "Lin_reg = LinearRegression()\n",
    "\n",
    "\n",
    "reg_list = [GBR,KR,BR,DT, Lin_SVR, Lin_reg, Log_reg, SGD,Poly_SVR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- top genre_alternative country\n- top genre_appalachian folk\n- top genre_beach music\n- top genre_big beat\n- top genre_classic country pop\n- ...\nFeature names seen at fit time, yet now missing:\n- top genre_acoustic blues\n- top genre_afrobeat\n- top genre_afropop\n- top genre_alternative rock\n- top genre_american folk revival\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg \u001b[38;5;129;01min\u001b[39;00m reg_list:\n\u001b[0;32m      2\u001b[0m     regressor \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m----> 3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:2120\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   2106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   2107\u001b[0m \n\u001b[0;32m   2108\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   2119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2120\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   2122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2123\u001b[0m     \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\riley\\OneDrive - University of Strathclyde\\AI and Applications\\.conda\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- top genre_alternative country\n- top genre_appalachian folk\n- top genre_beach music\n- top genre_big beat\n- top genre_classic country pop\n- ...\nFeature names seen at fit time, yet now missing:\n- top genre_acoustic blues\n- top genre_afrobeat\n- top genre_afropop\n- top genre_alternative rock\n- top genre_american folk revival\n- ...\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_list:\n",
    "    regressor = reg.fit(x_train,y_train)\n",
    "    y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
